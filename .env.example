# --- Target Repository ---
# BASE_DIR=/path/to/your/project

# --- Processing Mode ---
DIFF_ONLY=true

# --- Embedding Model Configuration (OpenAI-Compatible) ---
EMBEDDING_PROVIDER_NAME=openai
EMBEDDING_PROVIDER_BASE_URL=https://api.openai.com/v1
EMBEDDING_PROVIDER_API_KEY=sk-your_openai_key
EMBEDDING_MODEL=text-embedding-3-small
EMBEDDING_DIMENSIONS=1536
EMBEDDING_BATCH_SIZE=96
EMBEDDING_API_DELAY_MS=50 # Delay between embedding batches (ms)

# --- Code Analysis LLM Configuration (Azure OpenAI) ---
SUMMARY_RESOURCE_NAME=your_azure_resource_name
SUMMARY_DEPLOYMENT=your_gpt4_deployment_id
SUMMARY_API_KEY=your_azure_api_key
SUMMARY_API_DELAY_MS=1000 # Delay after each analysis call (ms) - useful for rate limiting

# --- Qdrant Configuration ---
QDRANT_URL=http://localhost:6333
QDRANT_API_KEY=
QDRANT_COLLECTION_NAME=my_code_embeddings
# QDRANT_USE_HTTPS=false
DISTANCE_METRIC=Cosine
UPSERT_BATCH_SIZE=100
DELETE_BATCH_SIZE=200

# --- Chunking & Concurrency Configuration ---
DEFAULT_CHUNK_SIZE=512
DEFAULT_CHUNK_OVERLAP=50
MAX_CONCURRENT_CHUNKING=5